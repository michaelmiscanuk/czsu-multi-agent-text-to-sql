# ===============================================================================
# CZSU MULTI-AGENT TEXT-TO-SQL APPLICATION ENVIRONMENT VARIABLES
# ===============================================================================
# This file contains all environment variables required for the CZSU Multi-Agent
# Text-to-SQL application. Never commit this file to version control with real API keys.
# Instead, create a .env.example file with placeholder values for team members.

# ===============================================================================
# MODEL API KEYS
# ===============================================================================
# Required API keys for different Large Language Model (LLM) providers.
# The application supports multiple LLM providers for flexibility and comparison.

# Azure OpenAI Configuration
# MODEL_PROVIDER=azureopenai
# Get these from: https://portal.azure.com -> Azure OpenAI Service
# AZURE_OPENAI_API_KEY: Your Azure OpenAI API key
# AZURE_OPENAI_ENDPOINT: Your Azure OpenAI resource endpoint URL
AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/

# Anthropic Claude Configuration
# MODEL_PROVIDER=anthropic
# Get API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY: Your Anthropic API key (starts with sk-ant-api03-)
ANTHROPIC_API_KEY=sk-ant-api03-your-anthropic-api-key-here

# Google Gemini Configuration
# MODEL_PROVIDER=gemini
# Get API key from: https://makersuite.google.com/app/apikey
# GOOGLE_API_KEY: Your Google AI API key
GOOGLE_API_KEY=your-google-api-key-here

# xAI Grok Configuration
# MODEL_PROVIDER=xai
# Get API key from: https://console.x.ai/
# XAI_API_KEY: Your xAI API key
XAI_API_KEY=xai-your-xai-api-key-here

# Mistral AI Configuration
# MODEL_PROVIDER=mistral
# Get API key from: https://console.mistral.ai/
# MISTRAL_API_KEY: Your Mistral AI API key
MISTRAL_API_KEY=your-mistral-api-key-here

# GitHub Models Configuration
# MODEL_PROVIDER=github
# Get token from: https://github.com/settings/tokens (Personal Access Token)
# See: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
# GITHUB_TOKEN: Your GitHub Personal Access Token (PAT)
GITHUB_TOKEN=github_pat_your-github-token-here

# ===============================================================================
# AZURE DOCUMENT INTELLIGENCE
# ===============================================================================
# Used for PDF document processing and text extraction
# Get from: https://portal.azure.com -> Azure AI Document Intelligence
# AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT: Your Document Intelligence endpoint
# AZURE_DOCUMENT_INTELLIGENCE_KEY: Your Document Intelligence API key
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-azure-document-intelligence-key-here

# ===============================================================================
# PHOENIX (Arize AI)
# ===============================================================================
# Used for LLM observability and tracing
# Get from: https://app.phoenix.arize.com
# PHOENIX_API_KEY: Your Phoenix API key
# PHOENIX_CLIENT_HEADERS: API key formatted for headers
# PHOENIX_COLLECTOR_ENDPOINT: Phoenix collector endpoint
PHOENIX_API_KEY=your-phoenix-api-key-here
PHOENIX_CLIENT_HEADERS=api_key=your-phoenix-api-key-here
PHOENIX_COLLECTOR_ENDPOINT=https://app.phoenix.arize.com

# ===============================================================================
# DEBUG SETTINGS
# ===============================================================================
# Control debug output for different components
# Set to 1 to enable debug logging, 0 to disable
DEBUG=0
print__nodes_debug=0
print__analysis_tracing_debug=0
print__tools_debug=0
print__analyze_debug=0
print__chat_all_messages_debug=0
print__chat_all_messages_one_thread_debug=0
print__feedback_debug=0
print__sentiment_debug=0
print__chat_threads_debug=0
print__chat_messages_debug=0
print__delete_chat_debug=0
print__chat_sentiments_debug=0
print__catalog_debug=0
print__data_tables_debug=0
print__data_table_debug=0
print__chat_thread_id_checkpoints_debug=0
print__debug_pool_status_debug=0
print__chat_thread_id_run_ids_debug=0
print__debug_run_id_debug=0
print__checkpointers_debug=0
print__memory_debug=0
print__main_debug=0
print__token_debug=0
print__api_postgresql=0
print__chromadb_debug=0
print__memory_monitoring=0

# ===============================================================================
# TESTING AND TRACEBACK LOGGING
# ===============================================================================
DEBUG_TRACEBACK=0  # During testing - Enable traceback to be included in error logs
CLEANED_TRACEBACK=0 # 1 = cleaned traceback in logs, 0 = full original traceback in logs

# AGENT
# Model configuration has been moved to my_agent/utils/node_models_config.py
# Each node (rewrite_prompt_node, generate_query_node, etc.) can now use a different model
# Edit the Python file to configure models for each node

# MAX_ITERATIONS=1
# MAX_TOOL_ITERATIONS=3
MAX_ITERATIONS=1
MAX_TOOL_ITERATIONS=3
MAX_QUERIES_LIMIT_FOR_REFLECT=10

# ===============================================================================
# ADDITIONAL SERVICE CONFIGURATIONS
# ===============================================================================
# LANGSMITH
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="your-langsmith-api-key-here"
LANGSMITH_PROJECT="for_czsu_multiagent_app"
LANGCHAIN_CALLBACKS_BACKGROUND=true

# MCP Server Configuration
MCP_SERVER_URL=https://double-violet-rooster.fastmcp.app/mcp
USE_LOCAL_SQLITE_FALLBACK="1"
FORCE_LOCAL_SQLITE="1"

# COHERE
COHERE_API_KEY="your-cohere-api-key-here"

# GOOGLE OAUTH
NEXTAUTH_URL=http://localhost:3000
GOOGLE_CLIENT_ID="your-google-client-id-here"
GOOGLE_CLIENT_SECRET="your-google-client-secret-here"
NEXTAUTH_SECRET="your-nextauth-secret-here"
NEXT_PUBLIC_API_BASE=http://localhost:8000

# Vercel
NEXT_PUBLIC_API_BASE=http://localhost:8000
NODE_ENV=development

# CORS Configuration
CORS_ALLOWED_ORIGINS=https://www.multiagent-texttosql-prototype.online,https://czsu-multi-agent-text-to-sql.vercel.app,http://localhost:3000,http://localhost:8000

# Python
PYTHON_VERSION=3.11.9

# ===============================================================================
# DATABASE CONFIGURATION
# ===============================================================================

# Supabase PostgreSQL connection (Transaction pooler)
# Used for user management, chat history, and application data
# password: Database password
# user: Database username
# host: Supabase pooler host
# port: Connection port
# dbname: Database name
# pool_mode: Connection pool mode
# Supabase - Transaction pooler
password=your-database-password-here
user=postgres.your-project-ref
host=aws-1-eu-central-2.pooler.supabase.com
port=6543
dbname=postgres
pool_mode=transaction

# PostgreSQL connection pool settings
# POSTGRES_POOL_MAX: Maximum connections in pool
# POSTGRES_POOL_MIN: Minimum connections in pool
# POSTGRES_POOL_TIMEOUT: Connection timeout in seconds
# CHECKPOINT_MAX_RETRIES: Number of retry attempts for checkpoints
# CHECKPOINT_RETRY_BASE_DELAY: Base delay between retries
# DBHANDLER_EXITED_DELAY_MULTIPLIER: Delay multiplier for DbHandler exited
# Postgres Pool Settings
POSTGRES_POOL_MAX=3
POSTGRES_POOL_MIN=1
POSTGRES_POOL_TIMEOUT=120
CHECKPOINT_MAX_RETRIES=3                      # Number of retry attempts
CHECKPOINT_RETRY_BASE_DELAY=0.5               # Base delay between retries  
DBHANDLER_EXITED_DELAY_MULTIPLIER=3           # Delay multiplier for DbHandler exited

# Python-specific memory optimization
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1
PYTHONHASHSEED=0
MALLOC_TRIM_THRESHOLD=100000


# UVICORN Settings
UVICORN_TIMEOUT_KEEP_ALIVE=30
UVICORN_TIMEOUT_GRACEFUL_SHUTDOWN=30

# ===============================================================================
# LLAMAPARSE
# ===============================================================================
# Used for advanced PDF parsing and document processing
# Get from: https://cloud.llamaindex.ai/
# LLAMAPARSE_API_KEY: Your LlamaParse API key
# LlamaParse
LLAMAPARSE_API_KEY=llx-your-llamaparse-api-key-here

# ===============================================================================
# CONCURRENCY SETTINGS
# ===============================================================================
# Control concurrent operations and threading
# MAX_CONCURRENT_ANALYSES: Maximum simultaneous analysis operations
# MAX_CONCURRENT_BULK_THREADS: Maximum threads for bulk operations
# Concurrency
MAX_CONCURRENT_ANALYSES=6
MAX_CONCURRENT_BULK_THREADS=10

# ===============================================================================
# MEMORY MANAGEMENT
# ===============================================================================
# Settings for memory optimization and monitoring
# GC_MEMORY_THRESHOLD: Garbage collection threshold in MB
# MEMORY_PROFILER_ENABLED: Enable memory profiling (1=yes, 0=no)
# MEMORY_PROFILER_INTERVAL: Profiling interval in seconds
# MEMORY_PROFILER_TOP_STATS: Number of top memory stats to show
# MEMORY_CLEANUP_ENABLED: Enable automatic memory cleanup (1=yes, 0=no)
# Memory
GC_MEMORY_THRESHOLD=1900
MEMORY_PROFILER_ENABLED=0
MEMORY_PROFILER_INTERVAL=60
MEMORY_PROFILER_TOP_STATS=30
MEMORY_CLEANUP_ENABLED=0

# ===============================================================================
# CHECKPOINTING AND FALLBACKS
# ===============================================================================
# InMemorySaver_fallback: Enable InMemorySaver fallback (1=yes, 0=no)
# USE_TEST_TOKENS: Allow use of test tokens (1=yes, 0=no)
# InMemorySaver Fallback
InMemorySaver_fallback=0

# Allow Testing Tokens
USE_TEST_TOKENS=1

# ===============================================================================
# TESTING CONFIGURATION
# ===============================================================================
# TEST_SERVER_URL: URL to run tests against (local or production)
# URL to run TESTS against
# TEST_SERVER_URL=http://localhost:8000
TEST_SERVER_URL=https://www.multiagent-texttosql-prototype.online/api

# ===============================================================================
# CHROMA VECTOR DATABASE
# ===============================================================================
# Cloud vector database for embeddings and similarity search
# Get from: https://trychroma.com/
# CHROMA_API_DATABASE: Database name
# CHROMA_API_KEY: API key for authentication
# CHROMA_API_TENANT: Tenant ID
# CHROMA_USE_CLOUD: Use cloud version (true/false)
# TRYCHROMA.COM
CHROMA_API_DATABASE="CZSU-Multi-Agent-Text-to-SQL"
CHROMA_API_KEY="your-chroma-api-key-here"
CHROMA_API_TENANT="your-chroma-tenant-id-here"
CHROMA_USE_CLOUD="true"

# ===============================================================================
# AZURE AI TRANSLATOR
# ===============================================================================
# Used for text translation between languages
# Get from: https://portal.azure.com -> Azure AI Translator
# TRANSLATOR_TEXT_SUBSCRIPTION_KEY: Azure Translator API key
# TRANSLATOR_TEXT_REGION: Azure region (e.g., swedencentral, westeurope)
# TRANSLATOR_TEXT_ENDPOINT: Translator service endpoint
# Azure AI Translator via Azure Foundry
TRANSLATOR_TEXT_SUBSCRIPTION_KEY=your-azure-translator-subscription-key-here
TRANSLATOR_TEXT_REGION=swedencentral
TRANSLATOR_TEXT_ENDPOINT=https://api.cognitive.microsofttranslator.com/

# ===============================================================================
# SQLITE CLOUD
# ===============================================================================
# Cloud-hosted SQLite database for CZSU data
# Get from: https://sqlitecloud.io/
# SQLITECLOUD_API_KEY: SQLite Cloud API key
# SQLITECLOUD_PROJECT_ID: Project identifier
# SQLITECLOUD_HOST_PORT: Host and port for connection
# SQLITECLOUD_DATABASE_NAME: Database name
# SQLite Cloud
SQLITECLOUD_API_KEY=your-sqlitecloud-api-key-here
SQLITECLOUD_PROJECT_ID=your-project-id.g3
SQLITECLOUD_HOST_PORT=8860
SQLITECLOUD_DATABASE_NAME=czsu_data.db

# ===============================================================================
# TURSO
# ===============================================================================
# Edge database for global data access
# Get from: https://turso.tech/
# TURSO_API_KEY: Turso API key (JWT token)
TURSO_API_KEY=your-turso-api-key-jwt-token-here

# ===============================================================================
# ADDITIONAL AZURE SERVICES
# ===============================================================================
# Azure Document Intelligence (already configured above)
# AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT: Document Intelligence endpoint
# AZURE_DOCUMENT_INTELLIGENCE_KEY: Document Intelligence API key
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource-name.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-azure-document-intelligence-key-here

# ===============================================================================
# APPLICATION FEATURES
# ===============================================================================

# FOLLOWUP PROMPTS CONFIGURATION
# Strategy for generating initial followup prompts for new conversations
# Options: "template" (default, fast, no API calls) or "ai" (uses GPT-4o-mini, more creative)
FOLLOWUP_PROMPTS_STRATEGY=ai
